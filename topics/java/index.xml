<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Java on Cindy&#39;s Blog</title>
    <link>http://xmxiaohuilin.github.io/topics/java/</link>
    <description>Recent content in Java on Cindy&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>(c) 2015 Cindy Lin.</copyright>
    <lastBuildDate>Thu, 12 Nov 2015 22:56:15 -0700</lastBuildDate>
    <atom:link href="http://xmxiaohuilin.github.io/topics/java/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Hadoop Review</title>
      <link>http://xmxiaohuilin.github.io/code/reviewHadoop/</link>
      <pubDate>Thu, 12 Nov 2015 22:56:15 -0700</pubDate>
      
      <guid>http://xmxiaohuilin.github.io/code/reviewHadoop/</guid>
      <description>

&lt;h2 id=&#34;what-is-hadoop&#34;&gt;What is Hadoop&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;An open-source software framework for storage and large-scale processing of data-sets on clusters of commodity hardware&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/xmruibi/Sketchboard/master/hadoopInfra.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;physical-hardware-level&#34;&gt;Physical Hardware Level&lt;/h2&gt;

&lt;p&gt;This is the hardware part of the infrastructure.&lt;/p&gt;

&lt;h3 id=&#34;cluster&#34;&gt;Cluster&lt;/h3&gt;

&lt;p&gt;Cluster is the set of host machines (nodes). Nodes may be partitioned in racks.&lt;/p&gt;

&lt;h2 id=&#34;hardware-management-level&#34;&gt;Hardware Management Level&lt;/h2&gt;

&lt;p&gt;This level contains the functions for manipulate the physical resources, management on data resources and static storage for data resources.&lt;/p&gt;

&lt;h3 id=&#34;yarn&#34;&gt;YARN&lt;/h3&gt;

&lt;p&gt;YARN Infrastructure (Yet Another Resource Negotiator) is to do the Computational Resources Allocation. We can also regard it as a data operating system.&lt;/p&gt;

&lt;h5 id=&#34;resource-manager-one-per-cluster-is-the-master&#34;&gt;&lt;strong&gt;Resource Manager&lt;/strong&gt; (one per cluster) is the master.&lt;/h5&gt;

&lt;p&gt;Knows how many resources they have.
- Scheduler
- Heartbeat Monitor&lt;/p&gt;

&lt;h5 id=&#34;node-manager-many-per-cluster-is-the-slave-of-the-infrastructure&#34;&gt;&lt;strong&gt;Node Manager&lt;/strong&gt; (many per cluster) is the slave of the infrastructure.&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Heartbeat Sender&lt;/em&gt;&lt;br /&gt;
Periodically, it sends an heartbeat to the Resource Manager.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Container Management&lt;/em&gt;&lt;br /&gt;
A fraction of the NM capacity and it is used by the client for running a program.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;hdfs&#34;&gt;HDFS&lt;/h3&gt;

&lt;p&gt;File System for providing permanent, reliable and distributed storage. This is typically used for storing inputs and output (but not intermediate ones).&lt;/p&gt;

&lt;h3 id=&#34;storage&#34;&gt;Storage&lt;/h3&gt;

&lt;p&gt;Alternative storage solutions. For instance, Database (like &lt;strong&gt;MongoDB&lt;/strong&gt;) or Simple Storage Service (S3).&lt;/p&gt;

&lt;h2 id=&#34;software-level-map-reduce&#34;&gt;Software Level (Map Reduce)&lt;/h2&gt;

&lt;p&gt;This level mainly focus on the data processing by implementing the &lt;strong&gt;MapReduce&lt;/strong&gt; paradigm.&lt;/p&gt;

&lt;h3 id=&#34;before-mapreduce-job&#34;&gt;Before MapReduce Job&lt;/h3&gt;

&lt;p&gt;When a client submits an application, several kinds of information are provided to the YARN infrastucture. In particular:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Configuration:&lt;br /&gt;
This may be partial (some parameters are not specified by the user) and in this case the default values are used for the job. Notice that these default values may be the ones chosen by a Hadoop provider like Amanzon.&lt;/li&gt;
&lt;li&gt;Java Implementation:

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;map()&lt;/code&gt; implementation&lt;/li&gt;
&lt;li&gt;&lt;code&gt;combiner()&lt;/code&gt; implementation&lt;/li&gt;
&lt;li&gt;&lt;code&gt;reduce()&lt;/code&gt; implementation&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Input/Output information:

&lt;ul&gt;
&lt;li&gt;Input URL:&lt;br /&gt;
Is the input directory on HDFS? On DB? How many files?&lt;/li&gt;
&lt;li&gt;Output URL:&lt;br /&gt;
Where will we store the output? On HDFS? On DB?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;interaction-between-mapreduce-framework-and-yarn-infrastructure&#34;&gt;Interaction between MapReduce Framework and YARN Infrastructure&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://xmxiaohuilin.github.io/media/hadoop/MR-Yarn.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;overview-of-map-reduce-function&#34;&gt;Overview of Map Reduce function&lt;/h3&gt;

&lt;p&gt;It is organized as a “map” function which transform a piece of data into some number of key/value pairs. Each of these elements will then be sorted by their key and reach to the same node, where a “reduce” function is use to merge the values (of the same key) into a single result.&lt;/p&gt;

&lt;h3 id=&#34;mapper&#34;&gt;Mapper&lt;/h3&gt;

&lt;p&gt;Mapper maps input key/value pairs to a set of intermediate key/value pairs.&lt;/p&gt;

&lt;p&gt;Maps are the individual tasks that transform input records into intermediate records. The transformed intermediate records do not need to be of the same type as the input records. A given input pair may map to zero or many output pairs.&lt;/p&gt;

&lt;p&gt;The following comes from one of Chinese blog:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在map task执行时，它的输入数据来源于HDFS的block，当然在MapReduce概念中，map task只读取split。Split与block的对应关系可能是多对一，默认是一对一。在WordCount例子里，假设map的输入数据都是像“aaa”这样的字符串。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;在经过mapper的运行后，我们得知mapper的输出是这样一个key/value对： key是“aaa”， value是数值1。因为当前map端只做加1的操作，在reduce task里才去合并结果集。前面我们知道这个job有3个reduce task，到底当前的“aaa”应该交由哪个reduce去做呢，是需要现在决定的。&lt;/p&gt;

&lt;p&gt;MapReduce提供Partitioner接口，它的作用就是根据key或value及reduce的数量来决定当前的这对输出数据最终应该交由哪个reduce task处理。默认对key hash后再以reduce task数量取模。默认的取模方式只是为了平均reduce的处理能力，如果用户自己对Partitioner有需求，可以订制并设置到job上。&lt;/p&gt;

&lt;p&gt;在我们的例子中，“aaa”经过Partitioner后返回0，也就是这对值应当交由第一个reducer来处理。接下来，需要将数据写入内存缓冲区中，缓冲区的作用是批量收集map结果，减少磁盘IO的影响。我们的key/value对以及Partition的结果都会被写入缓冲区。当然写入之前，key与value值都会被序列化成字节数组。&lt;/p&gt;

&lt;p&gt;整个内存缓冲区就是一个字节数组，它的字节索引及key/value存储结构我没有研究过。如果有朋友对它有研究，那么请大致描述下它的细节吧。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;这个内存缓冲区是有大小限制的，默认是100MB。当map task的输出结果很多时，就可能会撑爆内存，所以需要在一定条件下将缓冲区中的数据临时写入磁盘，然后重新利用这块缓冲区。这个从内存往磁盘写数据的过程被称为Spill，中文可译为溢写，字面意思很直观。这个溢写是由单独线程来完成，不影响往缓冲区写map结果的线程。溢写线程启动时不应该阻止map的结果输出，所以整个缓冲区有个溢写的比例spill.percent。这个比例默认是0.8，也就是当缓冲区的数据已经达到阈值（buffer size * spill percent = 100MB * 0.8 = 80MB），溢写线程启动，锁定这80MB的内存，执行溢写过程。Map task的输出结果还可以往剩下的20MB内存中写，互不影响。当溢写线程启动后，需要对这80MB空间内的key做排序(Sort)。排序是MapReduce模型默认的行为，这里的排序也是对序列化的字节做的排序。&lt;/p&gt;

&lt;p&gt;在这里我们可以想想，因为map task的输出是需要发送到不同的reduce端去，而内存缓冲区没有对将发送到相同reduce端的数据做合并，那么这种合并应该是体现是磁盘文件中的。从官方图上也可以看到写到磁盘中的溢写文件是对不同的reduce端的数值做过合并。所以溢写过程一个很重要的细节在于，如果有很多个key/value对需要发送到某个reduce端去，那么需要将这些key/value值拼接到一块，减少与partition相关的索引记录。&lt;/p&gt;

&lt;p&gt;在针对每个reduce端而合并数据时，有些数据可能像这样：“aaa”/1， “aaa”/1。对于WordCount例子，就是简单地统计单词出现的次数，如果在同一个map task的结果中有很多个像“aaa”一样出现多次的key，我们就应该把它们的值合并到一块，这个过程叫reduce也叫combine。但MapReduce的术语中，reduce只指reduce端执行从多个map task取数据做计算的过程。除reduce外，非正式地合并数据只能算做combine了。其实大家知道的，MapReduce中将Combiner等同于Reducer。&lt;/p&gt;

&lt;p&gt;如果client设置过Combiner，那么现在就是使用Combiner的时候了。将有相同key的key/value对的value加起来，减少溢写到磁盘的数据量。Combiner会优化MapReduce的中间结果，所以它在整个模型中会多次使用。那哪些场景才能使用Combiner呢？从这里分析，Combiner的输出是Reducer的输入，Combiner绝不能改变最终的计算结果。所以从我的想法来看，Combiner只应该用于那种Reduce的输入key/value与输出key/value类型完全一致，且不影响最终结果的场景。比如累加，最大值等。Combiner的使用一定得慎重，如果用好，它对job执行效率有帮助，反之会影响reduce的最终结果。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;每次溢写会在磁盘上生成一个溢写文件，如果map的输出结果真的很大，有多次这样的溢写发生，磁盘上相应的就会有多个溢写文件存在。当map task真正完成时，内存缓冲区中的数据也全部溢写到磁盘中形成一个溢写文件。最终磁盘中会至少有一个这样的溢写文件存在(如果map的输出结果很少，当map执行完成时，只会产生一个溢写文件)，因为最终的文件只有一个，所以需要将这些溢写文件归并到一起，这个过程就叫做Merge。Merge是怎样的？如前面的例子，“aaa”从某个map task读取过来时值是5，从另外一个map 读取时值是8，因为它们有相同的key，所以得merge成group。什么是group。对于“aaa”就是像这样的：{“aaa”, [5, 8, 2, …]}，数组中的值就是从不同溢写文件中读取出来的，然后再把这些值加起来。请注意，因为merge是将多个溢写文件合并到一个文件，所以可能也有相同的key存在，在这个过程中如果client设置过Combiner，也会使用Combiner来合并相同的key。&lt;br /&gt;
至此，map端的所有工作都已结束，最终生成的这个文件也存放在TaskTracker够得着的某个本地目录内。每个reduce task不断地通过RPC从JobTracker那里获取map task是否完成的信息，如果reduce task得到通知，获知某台TaskTracker上的map task执行完成，Shuffle的后半段过程开始启动。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;简单地说，reduce task在执行之前的工作就是不断地拉取当前job里每个map task的最终结果，然后对从不同地方拉取过来的数据不断地做merge，也最终形成一个文件作为reduce task的输入文件。&lt;/p&gt;

&lt;h3 id=&#34;reducer&#34;&gt;Reducer&lt;/h3&gt;

&lt;p&gt;Reducer reduces a set of intermediate values which share a key to a smaller set of values.&lt;/p&gt;

&lt;p&gt;The following comes from one of Chinese blog:
Reducer真正运行之前，所有的时间都是在拉取数据，做merge，且不断重复地在做。如前面的方式一样，下面我也分段地描述reduce 端的Shuffle细节：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Copy过程，简单地拉取数据。Reduce进程启动一些数据copy线程(Fetcher)，通过HTTP方式请求map task所在的TaskTracker获取map task的输出文件。因为map task早已结束，这些文件就归TaskTracker管理在本地磁盘中。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Merge阶段。这里的merge如map端的merge动作，只是数组中存放的是不同map端copy来的数值。Copy过来的数据会先放入内存缓冲区中，这里的缓冲区大小要比map端的更为灵活，它基于JVM的heap size设置，因为Shuffle阶段Reducer不运行，所以应该把绝大部分的内存都给Shuffle用。这里需要强调的是，merge有三种形式：1)内存到内存  2)内存到磁盘  3)磁盘到磁盘。默认情况下第一种形式不启用，让人比较困惑，是吧。当内存中的数据量到达一定阈值，就启动内存到磁盘的merge。与map 端类似，这也是溢写的过程，这个过程中如果你设置有Combiner，也是会启用的，然后在磁盘中生成了众多的溢写文件。第二种merge方式一直在运行，直到没有map端的数据时才结束，然后启动第三种磁盘到磁盘的merge方式生成最终的那个文件。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Reducer的输入文件。不断地merge后，最后会生成一个“最终文件”。为什么加引号？因为这个文件可能存在于磁盘上，也可能存在于内存中。对我们来说，当然希望它存放于内存中，直接作为Reducer的输入，但默认情况下，这个文件是存放于磁盘中的。当Reducer的输入文件已定，整个Shuffle才最终结束。然后就是Reducer执行，把结果放到HDFS上。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;procedure&#34;&gt;Procedure&lt;/h3&gt;

&lt;h5 id=&#34;my-handwriting-procedure-about-how-mapreduce-works&#34;&gt;My handwriting procedure about how MapReduce works.&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/xmruibi/Sketchboard/master/map_reduce.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://4.bp.blogspot.com/_j6mB7TMmJJY/SS0CEJLklnI/AAAAAAAAAGQ/ogPGJ3WYpt4/s1600-h/P4.png&#34;&gt;Map Reduce Procedure Model&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://langyu.iteye.com/blog/992916&#34;&gt;MapReduce:详解Shuffle过程&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://hadoop.apache.org/docs/r2.6.1/index.html&#34;&gt;Hadoop Official Site&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mutex vs Semaphore</title>
      <link>http://xmxiaohuilin.github.io/2015/11/12/mutex-vs-semaphore/</link>
      <pubDate>Thu, 12 Nov 2015 09:03:07 -0700</pubDate>
      
      <guid>http://xmxiaohuilin.github.io/2015/11/12/mutex-vs-semaphore/</guid>
      <description>

&lt;h2 id=&#34;what-are-the-differences-between-mutex-vs-semaphore-when-to-use-mutex-and-when-to-use-semaphore&#34;&gt;What are the differences between Mutex vs Semaphore? When to use mutex and when to use semaphore?&lt;/h2&gt;

&lt;p&gt;As per operating system terminology, mutex and semaphore are kernel resources that provide synchronization services (also called as synchronization primitives). Why do we need such synchronization primitives? Won’t be only one sufficient? To answer these questions, we need to understand few keywords. Please read the posts on atomicity and critical section. We will illustrate with examples to understand these concepts well, rather than following usual OS textual description.&lt;/p&gt;

&lt;h2 id=&#34;the-producer-consumer-problem&#34;&gt;The producer-consumer problem:&lt;/h2&gt;

&lt;p&gt;Note that the content is generalized explanation. Practical details vary with implementation.&lt;/p&gt;

&lt;p&gt;Consider the standard producer-consumer problem. Assume, we have a buffer of 4096 byte length. A producer thread collects the data and writes it to the buffer. A consumer thread processes the collected data from the buffer. Objective is, both the threads should not run at the same time.&lt;/p&gt;

&lt;h3 id=&#34;using-mutex&#34;&gt;Using Mutex:&lt;/h3&gt;

&lt;p&gt;A mutex provides mutual exclusion, either producer or consumer can have the key (mutex) and proceed with their work. As long as the buffer is filled by producer, the consumer needs to wait, and vice versa.&lt;/p&gt;

&lt;p&gt;At any point of time, only one thread can work with the entire buffer. The concept can be generalized using semaphore.&lt;/p&gt;

&lt;h3 id=&#34;using-semaphore&#34;&gt;Using Semaphore:&lt;/h3&gt;

&lt;p&gt;A semaphore is a generalized mutex. In lieu of single buffer, we can split the 4 KB buffer into four 1 KB buffers (identical resources). A semaphore can be associated with these four buffers. The consumer and producer can work on different buffers at the same time.&lt;/p&gt;

&lt;h2 id=&#34;misconception&#34;&gt;Misconception:&lt;/h2&gt;

&lt;p&gt;There is an ambiguity between binary semaphore and mutex. We might have come across that a mutex is binary semaphore. But they are not! The purpose of mutex and semaphore are different. May be, due to similarity in their implementation a mutex would be referred as binary semaphore.&lt;/p&gt;

&lt;h3 id=&#34;mutex-locking-mechanism&#34;&gt;Mutex - locking mechanism&lt;/h3&gt;

&lt;p&gt;Strictly speaking, a mutex is locking mechanism used to synchronize access to a resource. Only one task (can be a thread or process based on OS abstraction) can acquire the mutex. It means there is ownership associated with mutex, and only the owner can release the lock (mutex).&lt;/p&gt;

&lt;h3 id=&#34;code-of-mutex&#34;&gt;Code of Mutex&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Mutex {
    private MutexStatus mutexStatus;

    public Mutex() {
        mutexStatus = MutexStatus.FREE;
    }

    public void acquire() {
        synchronized (this) {
            if (mutexStatus == MutexStatus.BUSY)
                wait();
            mutexStatus = MutexStatus.BUSY;
        }
    }

    public void release() {
        mutexStatus = MutexStatus.FREE;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;semaphore-signaling-mechanism&#34;&gt;Semaphore - signaling mechanism&lt;/h3&gt;

&lt;p&gt;Semaphore is signaling mechanism &lt;strong&gt;(“I am done, you can carry on” kind of signal)&lt;/strong&gt;. For example, if you are listening songs (assume it as one task) on your mobile and at the same time your friend calls you, an interrupt is triggered upon which an interrupt service routine (ISR) signals the call processing task to wakeup.&lt;/p&gt;

&lt;h3 id=&#34;code-of-semaphore&#34;&gt;Code of Semaphore&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class BoundedSemaphore {
  private int signals = 0;
  private int bound   = 0;

  public BoundedSemaphore(int upperBound){
    this.bound = upperBound;
  }

  public synchronized void take() throws InterruptedException{
    while(this.signals == bound) wait();
    this.signals++;
    this.notify();
  }

  public synchronized void release() throws InterruptedException{
    while(this.signals == 0) wait();
    this.signals--;
    this.notify();
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;general-questions&#34;&gt;General Questions:&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Can a thread acquire more than one lock (Mutex)?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Yes, it is possible that a thread is in need of more than one resource, hence the locks. If any lock is not available the thread will wait (block) on the lock.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Can a mutex be locked more than once?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;A mutex is a lock. Only one state (locked/unlocked) is associated with it. However, a recursive mutex can be locked more than once (POSIX complaint systems), in which a count is associated with it, yet retains only one state (locked/unlocked). The programmer must unlock the mutex as many number times as it was locked.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;What happens if a non-recursive mutex is locked more than once.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Deadlock. If a thread which had already locked a mutex, tries to lock the mutex again, it will enter into the waiting list of that mutex, which results in deadlock. It is because no other thread can unlock the mutex. An operating system implementer can exercise care in identifying the owner of mutex and return if it is already locked by same thread to prevent deadlocks.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Are binary semaphore and mutex same?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;No. We suggest to treat them separately, as it is explained signalling vs locking mechanisms. But a binary semaphore may experience the same critical issues (e.g. priority inversion) associated with mutex. We will cover these in later article.&lt;/p&gt;

&lt;p&gt;A programmer can prefer mutex rather than creating a semaphore with count 1.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;What is a mutex and critical section?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Some operating systems use the same word critical section in the API. Usually a mutex is costly operation due to protection protocols associated with it. At last, the objective of mutex is atomic access. There are other ways to achieve atomic access like disabling interrupts which can be much faster but ruins responsiveness. The alternate API makes use of disabling interrupts.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;What are events?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The semantics of mutex, semaphore, event, critical section, etc… are same. All are synchronization primitives. Based on their cost in using them they are different. We should consult the OS documentation for exact details.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Can we acquire mutex/semaphore in an Interrupt Service Routine?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;An ISR will run asynchronously in the context of current running thread. It is not recommended to query (blocking call) the availability of synchronization primitives in an ISR. The ISR are meant be short, the call to mutex/semaphore may block the current running thread. However, an ISR can signal a semaphore or unlock a mutex.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;What we mean by “thread blocking on mutex/semaphore” when they are not available?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Every synchronization primitive has a waiting list associated with it. When the resource is not available, the requesting thread will be moved from the running list of processor to the waiting list of the synchronization primitive. When the resource is available, the higher priority thread on the waiting list gets the resource (more precisely, it depends on the scheduling policies).&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Is it necessary that a thread must block always when resource is not available?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Not necessary. If the design is sure ‘what has to be done when resource is not available‘, the thread can take up that work (a different code branch). To support application requirements the OS provides non-blocking API.&lt;/p&gt;

&lt;p&gt;For example POSIX pthread_mutex_trylock() API. When mutex is not available the function returns immediately whereas the API pthread_mutex_lock() blocks the thread till resource is available.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Double Type and Float Type</title>
      <link>http://xmxiaohuilin.github.io/2015/11/12/double-type-and-float-type/</link>
      <pubDate>Thu, 12 Nov 2015 00:03:07 -0700</pubDate>
      
      <guid>http://xmxiaohuilin.github.io/2015/11/12/double-type-and-float-type/</guid>
      <description>

&lt;p&gt;Float number and Double number are always a headache for Java developer. Lots of traps inside of these two types. Let&amp;rsquo;s see how it works inside on physical memory and software layer.&lt;/p&gt;

&lt;h2 id=&#34;memory-structure&#34;&gt;Memory Structure&lt;/h2&gt;

&lt;h3 id=&#34;float&#34;&gt;Float:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;1 bit for Sign&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;8 bits Exponent (-128~+127) (complement)&lt;/li&gt;
&lt;li&gt;23 bits Integer&lt;br /&gt;
&lt;code&gt;
	| 1  |    8    |         23       |
	|sign| exponent|       number     |
&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;double&#34;&gt;Double:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;1 bit for Sign&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;11 bits Exponent (-1024~+1023) (complement)&lt;/li&gt;
&lt;li&gt;52 bits Integer&lt;br /&gt;
&lt;code&gt;
	| 1  |     11    |         52        |
	|sign|  exponent |        number     |
&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;accuracy&#34;&gt;Accuracy&lt;/h2&gt;

&lt;p&gt;float和double的精度是由尾数的位数来决定的。浮点数在内存中是按科学计数法来存储的，其整数部分始终是一个隐含着的“1”，由于它是不变的，故不能对精度造成影响。&lt;/p&gt;

&lt;p&gt;float：2^23 = 8388608，一共七位，由于最左为1的一位省略了，这意味着最多能表示8位数： 2*8388608 = 16777216 。有8位有效数字，但绝对能保证的为7位，也即float的精度为7~8位有效数字；&lt;/p&gt;

&lt;p&gt;double：2^52 = 4503599627370496，一共16位，同理，double的精度为16~17位。&lt;/p&gt;

&lt;p&gt;之所以不能用f1==f2来判断两个数相等，是因为虽然f1和f2在可能是两个不同的数字，但是受到浮点数表示精度的限制，有可能会错误的判断两个数相等！&lt;/p&gt;

&lt;p&gt;可以用下面这段代码检验一下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;		float f1 = 16777215f;  
		for (int i = 0; i &amp;lt; 10; i++) {  
		    System.out.println(f1);  
		    f1++;  
		}  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对于小数来说，更容易会因为精度而出错误。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;		float f = 2.2f;  
		double d = (double) f;  
		System.out.println(d);   
		f = 2.25f;  
		d = (double) f;  
		System.out.println(d);   
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        2.200000047683716
        2.25
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.25的单精度存储方式，转化为2进制位便是&lt;code&gt;10.01&lt;/code&gt;，整理为&lt;code&gt;1.001*2&lt;/code&gt; 很简单。
2.25的双精度表示为:&lt;code&gt;0 100 0000 0001 0010 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000&lt;/code&gt;,这样2.25在进行强制转换的时候，数值是不会变的。&lt;/p&gt;

&lt;p&gt;2.2用科学计数法表示应该为：将十进制的小数转换为二进制的小数的方法为将小数*2，取整数部分，所以0.282=0.4，所以二进制小数第一位为0.4的整数部分0，0.4×2=0.8，第二位为0,0.8*2=1.6,第三位为1，0.6×2 = 1.2，第四位为1，0.2*2=0.4，第五位为0，这样永远也不可能乘到=1.0，得到的二进制是一个无限循环的排列 00110011001100110011&amp;hellip; ,对于单精度数据来说，尾数只能表示24bit的精度，所以2.2的float存储为:
&lt;code&gt;0 1000 0001 001 1001 1001 1001 1001 1001&lt;/code&gt;. 但是这样存储方式，换算成十进制的值，却不会是2.2的，因为十进制在转换为二进制的时候可能会不准确，如2.2，而double类型的数据也存在同样的问题，所以在浮点数表示中会产生些许的误差，在单精度转换为双精度的时候，也会存在误差的问题。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Analysis  on HashMap API Source Code</title>
      <link>http://xmxiaohuilin.github.io/2015/10/22/analysis--on-hashmap-api-source-code/</link>
      <pubDate>Thu, 22 Oct 2015 00:03:07 -0700</pubDate>
      
      <guid>http://xmxiaohuilin.github.io/2015/10/22/analysis--on-hashmap-api-source-code/</guid>
      <description>

&lt;p&gt;Hash table based implementation of the Map interface.  This implementation provides all of the optional map operations, and permits &lt;code&gt;null&lt;/code&gt; values and the &lt;code&gt;null&lt;/code&gt; key.  (The HashMap class is roughly equivalent to Hashtable, except that it is unsynchronized and permits nulls.)  This class makes no guarantees as to the order of the map; in particular, it does not guarantee that the order will remain constant over time.&lt;/p&gt;

&lt;h2 id=&#34;how-hashmap-store-data&#34;&gt;How HashMap store data?&lt;/h2&gt;

&lt;h5 id=&#34;the-least-unit-in-hashmap-data-storage-is-the-entry-node-k-v-the-node-implements-map-entry-k-v&#34;&gt;The least unit in hashmap data storage is the &lt;code&gt;Entry Node&amp;lt;K,V&amp;gt;&lt;/code&gt;. The node implements &lt;code&gt;Map.Entry&amp;lt;K,V&amp;gt;&lt;/code&gt;&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; static class Node&amp;lt;K,V&amp;gt; implements Map.Entry&amp;lt;K,V&amp;gt; {
        final int hash;
        final K key;
        V value;
        // chaining address, point to next Entry Node
        Node&amp;lt;K,V&amp;gt; next;

        Node(int hash, K key, V value, Node&amp;lt;K,V&amp;gt; next) {
            this.hash = hash;
            this.key = key;
            this.value = value;
            this.next = next;
        }

        public final K getKey()        { return key; }
        public final V getValue()      { return value; }
        public final String toString() { return key + &amp;quot;=&amp;quot; + value; }

        public final int hashCode() {
            return Objects.hashCode(key) ^ Objects.hashCode(value);
        }

        public final V setValue(V newValue) {
            V oldValue = value;
            value = newValue;
            return oldValue;
        }

        public final boolean equals(Object o) {
            if (o == this)
                return true;
            if (o instanceof Map.Entry) {
                Map.Entry&amp;lt;?,?&amp;gt; e = (Map.Entry&amp;lt;?,?&amp;gt;)o;
                if (Objects.equals(key, e.getKey()) &amp;amp;&amp;amp;
                    Objects.equals(value, e.getValue()))
                    return true;
            }
            return false;
        }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;all-of-these-node-k-v-are-stored-in-table-as-a-node-array&#34;&gt;All of these &lt;code&gt;Node&amp;lt;K, V&amp;gt;&lt;/code&gt; are stored in &lt;code&gt;table&lt;/code&gt; as a Node Array&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;Nodes Array &lt;code&gt;Node&amp;lt;K, V&amp;gt;[] table&lt;/code&gt;
```java
/**

&lt;ul&gt;
&lt;li&gt;The table, initialized on first use, and resized as&lt;/li&gt;
&lt;li&gt;necessary. When allocated, length is always a power of two.&lt;/li&gt;
&lt;li&gt;(We also tolerate length zero in some operations to allow&lt;/li&gt;
&lt;li&gt;bootstrapping mechanics that are currently not needed.)
*/
transient Node&lt;K,V&gt;[] table;
```&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;however-hashmap-provides-three-views-for-retrieving-the-inside-data-keyset-values-and-entryset&#34;&gt;However, HashMap provides three views for retrieving the inside data: &lt;code&gt;keySet()&lt;/code&gt;, &lt;code&gt;values()&lt;/code&gt; and &lt;code&gt;entrySet()&lt;/code&gt;&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;KeySet: stores all keys in this hashmap
```java
/**&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;NOTE! This field is in AbstractMap class&lt;/li&gt;
&lt;li&gt;Each of these fields are initialized to contain an instance of the&lt;/li&gt;
&lt;li&gt;appropriate view the first time this view is requested.  The views are&lt;/li&gt;
&lt;li&gt;stateless, so there&amp;rsquo;s no reason to create more than one of each.
*/
transient volatile Set&lt;K&gt;        keySet;
```&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Values: stores all values in this hash Map
```java
/**&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;NOTE! This field is in AbstractMap class
*/
transient volatile Collection&lt;V&gt; values;
```&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;EntrySet: stores Entry Node(K-V pair) in this HashMap
```java
/**&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;This field is in HashMap class&lt;/li&gt;
&lt;li&gt;Holds cached entrySet(). Note that AbstractMap fields are used&lt;/li&gt;
&lt;li&gt;for keySet() and values().
*/
transient Set&lt;Map.Entry&lt;K,V&gt;&amp;gt; entrySet;
```&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;how-hashmap-manipulate-with-a-certain-k-v-pair&#34;&gt;How HashMap manipulate with a certain K-V pair?&lt;/h2&gt;

&lt;h3 id=&#34;insertion&#34;&gt;Insertion&lt;/h3&gt;

&lt;h5 id=&#34;here-is-the-public-entrance-put-key-value-to-insert-k-v-pair-into-hashmap-but-we-have-to-notice-it-has-the-return-value-which-is-the-previous-value-associated-with-this-key&#34;&gt;Here is the public entrance &lt;code&gt;put(key, value)&lt;/code&gt; to insert K - V pair into HashMap. But we have to notice it has the return value, which is the previous value associated with this key.&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    /**
     * @return the previous value associated with key, or
     *         null if there was no mapping for key.
     *         (A null return can also indicate that the map
     *         previously associated null with key.)
     */
    public V put(K key, V value) {
        return putVal(hash(key), key, value, false, true);
    }
    /**
     * The original version about put k-v pair node implement.
     * Notice those two boolean value
     * @param hash hash for key
     * @param key the key
     * @param value the value to put
     * @param onlyIfAbsent if true, don&#39;t change existing value
     * @param evict if false, the table is in creation mode.
     * @return previous value, or null if none
     */
    final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict){...}
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;i-made-a-lite-edition-about-putval-function-according-to-hashmap-source-code-the-main-procedure-on-insert-a-k-v-pair-to-hashmap-can-be-concluded-as-following&#34;&gt;I made a Lite Edition about &lt;code&gt;putVal&lt;/code&gt; function according to HashMap source code. The main procedure on insert a K-V pair to HashMap can be concluded as following:&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;Check the Entry Node table if it&amp;rsquo;s null, re-size it if necessary.&lt;/li&gt;
&lt;li&gt;Get the bucket index by &lt;code&gt;(table.length - 1) &amp;amp; hash&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Iterate the nodes in target bucket and check if there is any exist same node &lt;code&gt;exist.hash == hash &amp;amp;&amp;amp; ((prevKey = exist.key) == key || (key != null &amp;amp;&amp;amp; key.equals(prevKey))&lt;/code&gt;. If exist the node with the same key, update its value.&lt;/li&gt;
&lt;li&gt;Record the previous node of insert position for returning the previous value.&lt;/li&gt;
&lt;li&gt;Insert the new node and update the previous node next pointer: &lt;code&gt;prev.next = new Node(hash, key, value, null)&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
*  Lite Editon for HashMap input K - V pair function
**/
final V putVal(int hash, K key, V value) {
	// the reference for node table
	Node&amp;lt;K,V&amp;gt;[] tab; 
	// the reference for node in current bucket
	Node&amp;lt;K,V&amp;gt; prev;
    int n; // the table length
    
	if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
    int idx = (n - 1) &amp;amp; hash; // the bucket index
	if((prev = table[idx]) == null) {
		table[idx] = new Node(hash, key, value, null);
	}else {
		Node&amp;lt;K,V&amp;gt; exist; K prevKey;
		// if key equal to the first node in current bucket
		if(prev.hash == hash &amp;amp;&amp;amp; (prevKey = prev.key) == key || (key != null &amp;amp;&amp;amp; key.equals(prevKey)) {
			exist = prev;
		} else { 
			// find the top node in current bucket and iterate nodes in this bucket
			for (int binCount = 0; ; ++binCount) {
				// insert new node when find the next pointer of a node is null 
				if((exist = prev.next)  == null) {
					prev.next = new Node(hash, key, value, null);
					break;
				}
				// if any node in this bucket is the same as the insert one 
				if (exist.hash == hash &amp;amp;&amp;amp; ((prevKey = exist.key) == key || (key != null &amp;amp;&amp;amp; key.equals(prevKey))))
                    break;
                prev = exist;
			}
		}
		if (exist != null) { // existing mapping for key
            V oldValue = exist.value;
            if (oldValue == null)
                exist.value = value;
            return oldValue;
        }
	}
    // modification count for fail-fast
	++modCount;
	// check current node amount, if larger than threshodl do resize
    if (++size &amp;gt; threshold)
        resize();
    return null;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;retrieve&#34;&gt;Retrieve&lt;/h3&gt;

&lt;h5 id=&#34;the-public-entrance-get-key-returns-the-value-to-which-the-specified-key-is-mapped-or-null-if-this-map-contains-no-mapping-for-the-key-more-formally-if-this-map-contains-a-k-v-pair-key-null-then-this-method-returns-v-or-null-pleas-note-that-return-null-doesn-t-necessarily-indicates-the-map-contains-no-mapping-for-the-key-it-s-also-possible-that-the-map-explicitly-maps-the-key-to-null-source-code-shown-as-below&#34;&gt;The public entrance &lt;code&gt;get(key)&lt;/code&gt; returns the value to which the specified key is mapped, or null if this map contains no mapping for the key. More formally, if this map contains a K - V pair &lt;code&gt;key==null&lt;/code&gt; then this method returns &lt;code&gt;v&lt;/code&gt; or &lt;code&gt;null&lt;/code&gt;. Pleas note that return &lt;code&gt;null&lt;/code&gt; doesn&amp;rsquo;t necessarily indicates the map contains no mapping for the key! It&amp;rsquo;s also possible that the map explicitly maps the key to &lt;code&gt;NULL&lt;/code&gt;. Source code shown as below:&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    public V get(Object key) {
        Node&amp;lt;K,V&amp;gt; e;
        return (e = getNode(hash(key), key)) == null ? null : e.value;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;the-main-procedure-on-get-a-k-v-pair-to-hashmap-can-be-concluded-as-following&#34;&gt;The main procedure on get a K-V pair to HashMap can be concluded as following:&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;Get the index by hash code &lt;code&gt;(table.length - 1) &amp;amp; hash&lt;/code&gt; ;&lt;/li&gt;
&lt;li&gt;Check the first node in target bucket if it is the same as the input key and hash code&lt;/li&gt;
&lt;li&gt;Check the rest nodes iterative in target bucket if it matches the retrieval condition.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; final Node&amp;lt;K,V&amp;gt; getNode(int hash, Object key) {
        Node&amp;lt;K,V&amp;gt;[] tab; Node&amp;lt;K,V&amp;gt; first, e; int n; K k;
        if ((tab = table) != null &amp;amp;&amp;amp; (n = tab.length) &amp;gt; 0 &amp;amp;&amp;amp;
            (first = tab[(n - 1) &amp;amp; hash]) != null) {
            if (first.hash == hash &amp;amp;&amp;amp; // always check first node in the target bucket
                ((k = first.key) == key || (key != null &amp;amp;&amp;amp; key.equals(k))))
                return first;
            if ((e = first.next) != null) {
                do { // check the rest nodes in this bucket
                    if (e.hash == hash &amp;amp;&amp;amp;
                        ((k = e.key) == key || (key != null &amp;amp;&amp;amp; key.equals(k))))
                        return e;
                } while ((e = e.next) != null);
            }
        }
        return null;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;deletion&#34;&gt;Deletion&lt;/h3&gt;

&lt;h5 id=&#34;removes-the-mapping-for-the-specified-key-from-this-map-if-present-return-the-previous-value-associated-with-input-key-or-null-if-there-was-no-mapping-for-input-key-a-null-return-can-also-indicate-that-the-map-previously-associated-null-key&#34;&gt;Removes the mapping for the specified key from this map if present. Return the previous value associated with input key or &lt;code&gt;null&lt;/code&gt; if there was no mapping for input key (A &lt;code&gt;null&lt;/code&gt; return can also indicate that the map previously associated &lt;code&gt;null&lt;/code&gt; key).&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    public V remove(Object key) {
        Node&amp;lt;K,V&amp;gt; e;
        return (e = removeNode(hash(key), key, null, false, true)) == null ?
            null : e.value;
    }
    
    /**
     * The original version about remove node implement.
     * Notice those two boolean value
     * @param hash hash for key
     * @param key the key
     * @param value the value to match if matchValue, else ignored
     * @param matchValue if true only remove if value is equal
     * @param movable if false do not move other nodes while removing
     * @return the node, or null if none
     */
    final Node&amp;lt;K,V&amp;gt; removeNode(int hash, Object key, Object value,
                               boolean matchValue, boolean movable) {...}
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;implements-map-remove-and-related-methods-with-lite-version&#34;&gt;Implements Map.remove and related methods with lite version.&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    final Node&amp;lt;K,V&amp;gt; removeNode(int hash, Object key) {
        Node&amp;lt;K,V&amp;gt;[] tab; Node&amp;lt;K,V&amp;gt; p; int n, index;
        if ((tab = table) != null &amp;amp;&amp;amp; (n = tab.length) &amp;gt; 0 &amp;amp;&amp;amp;
            (p = tab[index = (n - 1) &amp;amp; hash]) != null) {
            Node&amp;lt;K,V&amp;gt; node = null, e; K k; V v;
            if (p.hash == hash &amp;amp;&amp;amp;
                ((k = p.key) == key || (key != null &amp;amp;&amp;amp; key.equals(k))))
                node = p;
            else if ((e = p.next) != null) {
                do {
                    if (e.hash == hash &amp;amp;&amp;amp; ((k = e.key) == key ||
                            (key != null &amp;amp;&amp;amp; key.equals(k)))) {
                        node = e;
                        break;
                    }
                        p = e;
                } while ((e = e.next) != null);
            }
            
            if (node != null ) {
                if (node == p)
                    tab[index] = node.next;
                else
                    p.next = node.next;
                ++modCount;
                --size;
                return node;
            }
        }
        return null;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;how-to-hash-by-key&#34;&gt;How to hash by key?&lt;/h2&gt;

&lt;h5 id=&#34;hash-function-is-very-important-to-hashmap-it-requires-quick-efficient-and-disperse-distribution-for-nodes&#34;&gt;Hash function is very important to HashMap. It requires quick, efficient and disperse distribution for nodes.&lt;/h5&gt;

&lt;blockquote&gt;
&lt;p&gt;Computes key.hashCode() and spreads (XORs) higher bits of hash to lower.  Because the table uses power-of-two masking, sets of hashes that vary only in bits above the current mask will always collide. (Among known examples are sets of Float keys holding consecutive whole numbers in small tables.)  So we apply a transform that spreads the impact of higher bits downward. There is a tradeoff between speed, utility, and quality of bit-spreading. Because many common sets of hashes are already reasonably distributed (so don&amp;rsquo;t benefit from spreading), and because we use trees to handle large sets of collisions in bins, we just XOR some shifted bits in the cheapest possible way to reduce systematic lossage, as well as to incorporate impact of the highest bits that would otherwise never be used in index calculations because of table bounds.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h &amp;gt;&amp;gt;&amp;gt; 16);
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;resize-and-rehash&#34;&gt;Resize and Rehash&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;final Node&amp;lt;K,V&amp;gt;[] resize() {
    Node&amp;lt;K, V&amp;gt; newtab = new Node&amp;lt;&amp;gt;[(table.length &amp;lt;&amp;lt; 1)];
    for(int i = 0; i &amp;lt; table.length; i++){
        Node&amp;lt;K, V&amp;gt; cur = table[i];
        while(cur != null) {
            Node&amp;lt;K, V&amp;gt; next = cur.next;
            cur.next = null;
            int newidx = cur.key.hashCode()%newtab.length;
            Node&amp;lt;K, V&amp;gt; prev = newtab[newidx];
            if(prev == null)
                newtab[newidx] = cur;
            else{
                while(prev.next != null)
                    prev = prev.next;
                prev.next = cur;
            }
            cur = next;
        }
    }
    table = newtab;
    return newtab;
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>What Is Good Java API</title>
      <link>http://xmxiaohuilin.github.io/2015/09/12/what-is-good-java-api/</link>
      <pubDate>Sat, 12 Sep 2015 00:00:00 -0700</pubDate>
      
      <guid>http://xmxiaohuilin.github.io/2015/09/12/what-is-good-java-api/</guid>
      <description>

&lt;p&gt;Here are some good points for designing a good Java API!&lt;/p&gt;

&lt;h2 id=&#34;rule-1-establish-strong-terms&#34;&gt;Rule #1: Establish strong terms&lt;/h2&gt;

&lt;p&gt;If your API grows, there will be repetitive use of the same terms, over and over again. For instance, some actions will be come in several flavours resulting in various classes / types / methods, that differ only subtly in behaviour. The fact that they’re similar should be reflected by their names. Names should use strong terms. Take JDBC for instance. No matter how you execute a Statement, you will always use the term execute to do it. For instance, you will call any of these methods:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;execute(String)
executeBatch()
executeQuery(String)
executeUpdate(String)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In a similar fashion, you will always use the term close to release resources, no matter which resource you’re releasing. For instance, you will call:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Connection.close()
Statement.close()
ResultSet.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As a matter of fact, close is such a strong and established term in the JDK, that it has lead to the interfaces java.io.Closeable (since Java 1.5), and java.lang.AutoCloseable (since Java 1.7), which generally establish a contract of releasing resources.&lt;/p&gt;

&lt;p&gt;Rule violation: Observable&lt;/p&gt;

&lt;p&gt;This rule is violated a couple of times in the JDK. For instance, in the java.util.Observable class. While other “Collection-like” types established the terms&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;size()
remove()
removeAll()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;… this class declares&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;countObservers()
deleteObserver(Observer)
deleteObservers()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There is no good reason for using other terms in this context. The same applies to Observer.update(), which should really be called notify(), an otherwise established term in JDK APIs&lt;/p&gt;

&lt;p&gt;Rule violation: Spring. Most of it&lt;/p&gt;

&lt;p&gt;Spring has really gotten popular in the days when J2EE was weird, slow, and cumbersome. Think about EJB 2.0… There may be similar opinions on Spring out there, which are off-topic for this post. Here’s how Spring violates this concrete rule. A couple of random examples where Spring fails to establish strong terms, and uses long concatenations of meaningless, inconcise words instead:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;AbstractBeanFactoryBasedTargetSourceCreator
AbstractInterceptorDrivenBeanDefinitionDecorator
AbstractRefreshablePortletApplicationContext
AspectJAdviceParameterNameDiscoverer
BeanFactoryTransactionAttributeSourceAdvisor
ClassPathScanningCandidateComponentProvider
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;… this could go on indefinitely, my favourite being …&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;J2eeBasedPreAuthenticatedWebAuthenticationDetailsSource
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Apart from “feeling” like a horrible API (to me), here’s some more objective analysis:&lt;/p&gt;

&lt;p&gt;What’s the difference between a Creator and a Factory
What’s the difference between a Source and a Provider?
What’s the non-subtle difference between an Advisor and a Provider?
What’s the non-subtle difference between a Discoverer and a Provider?
Is an Advisor related to an AspectJAdvice?
Is it a ScanningCandidate or a CandidateComponent?
What’s a TargetSource? And how would it be different from a SourceTarget if not a SourceSource or my favourite: A SourceSourceTargetProviderSource?
Gary Fleming commented on my previous blog post about Spring’s funny class names:&lt;/p&gt;

&lt;p&gt;I’d be willing to bet that a Markov-chain generated class name (based on Spring Security) would be indistinguishable from the real thing.&lt;/p&gt;

&lt;p&gt;Back to more seriousness…&lt;/p&gt;

&lt;h2 id=&#34;rule-2-apply-symmetry-to-term-combinations&#34;&gt;Rule #2: Apply symmetry to term combinations&lt;/h2&gt;

&lt;p&gt;Once you’ve established strong terms, you will start combining them. When you look at the JDK’s Collection APIs, you will notice the fact that they are symmetric in a way that they’ve established the terms add(), remove(), contains(), and all, before combining them symmetrically:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;add(E)
addAll(Collection&amp;lt;? extends E&amp;gt;)
remove(Object)
removeAll(Collection&amp;lt;?&amp;gt;)
contains(Object)
containsAll(Collection&amp;lt;?&amp;gt;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, the Collection type is a good example where an exception to this rule may be acceptable, when a method doesn’t “pull its own weight”. This is probably the case for retainAll(Collection&amp;lt;?&amp;gt;), which doesn’t have an equivalent retain(E) method. It might just as well be a regular violation of this rule, though.&lt;/p&gt;

&lt;p&gt;####Rule violation: Map&lt;/p&gt;

&lt;p&gt;This rule is violated all the time, mostly because of some methods not pulling their own weight (which is ultimately a matter of taste). With Java 8′s defender methods, there will no longer be any excuse of not adding default implementations for useful utility methods that should’ve been on some types. For instance: Map. It violates this rule a couple of times:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;It has keySet() and also containsKey(Object)&lt;/li&gt;
&lt;li&gt;It has values() and also containsValue(Object)&lt;/li&gt;
&lt;li&gt;It has entrySet() but no containsEntry(K, V)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Observe also, that there is no point of using the term Set in the method names. The method signature already indicates that the result has a Set type. It would’ve been more consistent and symmetric if those methods would’ve been named keys(), values(), entries(). (On a side-note, Sets and Lists are another topic that I will soon blog about, as I think those types do not pull their own weight either)&lt;/p&gt;

&lt;p&gt;At the same time, the Map interface violates this rule by providing&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;put(K, V) and also putAll(Map)&lt;/li&gt;
&lt;li&gt;remove(Object), but no removeAll(Collection&amp;lt;?&amp;gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Besides, establishing the term clear() instead of reusing removeAll() with no arguments is unnecessary. This applies to all Collection API members. In fact, the clear() method also violates rule #1. It is not immediately obvious, if clear does anything subtly different from remove when removing collection elements.&lt;/p&gt;

&lt;h2 id=&#34;rule-3-add-convenience-through-overloading&#34;&gt;Rule #3: Add convenience through overloading&lt;/h2&gt;

&lt;p&gt;There is mostly only one compelling reason, why you would want to overload a method: Convenience. Often you want to do precisely the same thing in different contexts, but constructing that very specific method argument type is cumbersome. So, for convenience, you offer your API users another variant of the same method, with a “friendlier” argument type set. This can be observed again in the Collection type. We have:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;toArray(), which is a convenient overload of…
toArray(T[])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Another example is the Arrays utility class. We have:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;copyOf(T[], int), which is an incompatible overload of…
copyOf(boolean[], int), and of…
copyOf(int[], int)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;… and all the others
Overloading is mostly used for two reasons:&lt;/p&gt;

&lt;p&gt;Providing “default” argument behaviour, as in Collection.toArray()
Supporting several incompatible, yet “similar” argument sets, as in Arrays.copyOf()
Other languages have incorporated these concepts into their language syntax. Many languages (e.g. PL/SQL) formally support named default arguments. Some languages (e.g. JavaScript) don’t even care how many arguments there really are. And another, new JVM language called Ceylon got rid of overloading by combining the support for named, default arguments with union types. As Ceylon is a statically typed language, this is probable the most powerful approach of adding convenience to your API.&lt;/p&gt;

&lt;p&gt;####Rule violation: TreeSet&lt;/p&gt;

&lt;p&gt;It is hard to find a good example of a case where this rule is violated in the JDK. But there is one: the TreeSet and TreeMap. Their constructors are overloaded several times. Let’s have a look at these two constructors:&lt;/p&gt;

&lt;p&gt;TreeSet(Collection&amp;lt;? extends E&amp;gt;)
TreeSet(SortedSet&lt;E&gt;)
The latter “cleverly” adds some convenience to the first in that it extracts a well-known Comparator from the argument SortedSet to preserve ordering. This behaviour is quite different from the compatible (!) first constructor, which doesn’t do an instanceof check of the argument collection. I.e. these two constructor calls result in different behaviour:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SortedSet&amp;lt;Object&amp;gt; original = // [...]
// Preserves ordering:
new TreeSet&amp;lt;Object&amp;gt;(original);
// Resets ordering:
new TreeSet&amp;lt;Object&amp;gt;((Collection&amp;lt;Object&amp;gt;) original);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These constructors violate the rule in that they produce completely different behaviour. They’re not just mere convenience.&lt;/p&gt;

&lt;h2 id=&#34;rule-4-consistent-argument-ordering&#34;&gt;Rule #4: Consistent argument ordering&lt;/h2&gt;

&lt;p&gt;Be sure that you consistently order arguments of your methods. This is an obvious thing to do for overloaded methods, as you can immediately see how it is better to always put the array first and the int after in the previous example from the Arrays utility class:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;copyOf(T[], int), which is an incompatible overload of…
copyOf(boolean[], int)
copyOf(int[], int)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;… and all the others
But you will quickly notice that all methods in that class will put the array being operated on first. Some examples:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;binarySearch(Object[], Object)
copyOfRange(T[], int, int)
fill(Object[], Object)
sort(T[], Comparator&amp;lt;? super T&amp;gt;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;####Rule violation: Arrays&lt;/p&gt;

&lt;p&gt;The same class also “subtly” violates this rule in that it puts optional arguments in between other arguments, when overloading methods. For instance, it declares&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fill(Object[], Object)
fill(Object[], int, int, Object)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When the latter should’ve been fill(Object[], Object, int, int). This is a “subtle” rule violation, as you may also argue that those methods in Arrays that restrict an argument array to a range will always put the array and the range argument together. In that way, the fill() method would again follow the rule as it provides the same argument order as copyOfRange(), for instance:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fill(Object[], int, int, Object)
copyOfRange(T[], int, int)
copyOfRange(T[], int, int, Class)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You will never be able to escape this problem if you heavily overload your API. Unfortunately, Java doesn’t support named parameters, which helps formally distinguishing arguments in a large argument list, as sometimes, large argument lists cannot be avoided.&lt;/p&gt;

&lt;p&gt;Rule violation: String&lt;/p&gt;

&lt;p&gt;Another case of a rule violation is the String class:&lt;/p&gt;

&lt;p&gt;regionMatches(int, String, int, int)
regionMatches(boolean, int, String, int, int)
The problems here are:&lt;/p&gt;

&lt;p&gt;It is hard to immediately understand the difference between the two methods, as the optional boolean argument is inserted at the beginning of the argument list
It is hard to immediately understand the purpose of every int argument, as there are many arguments in a single method&lt;/p&gt;

&lt;h2 id=&#34;rule-5-establish-return-value-types&#34;&gt;Rule #5: Establish return value types&lt;/h2&gt;

&lt;p&gt;This may be a bit controversial as people may have different views on this topic. No matter what your opinion is, however, you should create a consistent, regular API when it comes to defining return value types. An example rule set (on which you may disagree):&lt;/p&gt;

&lt;p&gt;Methods returning a single object should return null when no object was found
Methods returning several objects should return an empty List, Set, Map, array, etc. when no object was found (never null)
Methods should only throw exceptions in case of an … well, an exception
With such a rule set, it is not a good practice to have 1-2 methods lying around, which:&lt;/p&gt;

&lt;p&gt;… throw ObjectNotFoundExceptions when no object was found
… return null instead of empty Lists
Rule violation: File&lt;/p&gt;

&lt;p&gt;File is an example of a JDK class that violates many rules. Among them, the rule of regular return types. Its File.list() Javadoc reads:&lt;/p&gt;

&lt;p&gt;An array of strings naming the files and directories in the directory denoted by this abstract pathname. The array will be empty if the directory is empty. Returns null if this abstract pathname does not denote a directory, or if an I/O error occurs.&lt;/p&gt;

&lt;p&gt;So, the correct way to iterate over file names (if you’re doing defensive programming) is:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;String[] files = file.list();
// You should never forget this null check!
if (files != null) {
    for (String file : files) {
    // Do things with your file
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Of course, we could argue that the Java 5 expert group could’ve been nice with us and worked that null check into their implementation of the foreach loop. Similar to the missing null check when switching over an enum (which should lead to the default: case). They’ve probably preferred the “fail early” approach in this case.
The point here is that File already has sufficient means of checking if file is really a directory (File.isDirectory()). And it should throw an IOException if something went wrong, instead of returning null. This is a very strong violation of this rule, causing lots of pain at the call-site… Hence:&lt;/p&gt;

&lt;p&gt;NEVER return null when returning arrays or collections!&lt;/p&gt;

&lt;p&gt;####Rule violation: JPA&lt;/p&gt;

&lt;p&gt;An example of how JPA violates this rule is the way how entities are retrieved from the EntityManager or from a Query:&lt;/p&gt;

&lt;p&gt;EntityManager.find() methods return null if no entity could be found
Query.getSingleResult() throws a NoResultException if no entity could be found
As NoResultException is a RuntimeException this flaw heavily violates the Principle of Least Astonishment, as you might stay unaware of this difference until runtime!&lt;/p&gt;

&lt;p&gt;IF you insist on throwing NoResultExceptions, make them checked exceptions as client code MUST handle them&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Immutable Classes</title>
      <link>http://xmxiaohuilin.github.io/2015/08/11/immutable-classes/</link>
      <pubDate>Tue, 11 Aug 2015 23:57:44 -0700</pubDate>
      
      <guid>http://xmxiaohuilin.github.io/2015/08/11/immutable-classes/</guid>
      <description>

&lt;h3 id=&#34;what-is-immutable-classes&#34;&gt;What is Immutable Classes&lt;/h3&gt;

&lt;p&gt;不可变对象（immutable objects），后面文章我将使用immutable objects来代替不可变对象！&lt;/p&gt;

&lt;p&gt;那么什么是immutable objects?什么又是mutable Objects呢？&lt;/p&gt;

&lt;p&gt;immutable Objects就是那些一旦被创建，它们的状态就不能被改变的Objects，每次对他们的改变都是产生了新的immutable的对象，而mutable Objects就是那些创建后，状态可以被改变的Objects.&lt;/p&gt;

&lt;p&gt;举个例子：String和StringBuilder，String是immutable的，每次对于String对象的修改都将产生一个新的String对象，而原来的对象保持不变，而StringBuilder是mutable，因为每次对于它的对象的修改都作用于该对象本身，并没有产生新的对象。&lt;/p&gt;

&lt;p&gt;但有的时候String的immutable特性也会引起安全问题，这就是密码应该存放在字符数组中而不是String中的原因！&lt;/p&gt;

&lt;p&gt;immutable objects 比传统的mutable对象在多线程应用中更具有优势，它不仅能够保证对象的状态不被改变，而且还可以不使用锁机制就能被其他线程共享。&lt;/p&gt;

&lt;p&gt;实际上JDK本身就自带了一些immutable类，比如String，Integer以及其他包装类。为什么说String是immutable的呢？比如：java.lang.String 的trim，uppercase,substring等方法，它们返回的都是新的String对象，而并不是直接修改原来的对象。&lt;/p&gt;

&lt;p&gt;如何在Java中写出Immutable的类？&lt;/p&gt;

&lt;p&gt;要写出这样的类，需要遵循以下几个原则：&lt;/p&gt;

&lt;p&gt;1）immutable对象的状态在创建之后就不能发生改变，任何对它的改变都应该产生一个新的对象。&lt;/p&gt;

&lt;p&gt;2）Immutable类的所有的field都应该是final的。&lt;/p&gt;

&lt;p&gt;3）对象必须被正确的创建，比如：对象引用在对象创建过程中不能泄露(leak)。&lt;/p&gt;

&lt;p&gt;4）对象应该是final的，以此来限制子类继承父类，以避免子类改变了父类的immutable特性。&lt;/p&gt;

&lt;p&gt;5）如果类中包含mutable类对象，那么返回给客户端的时候，返回该对象的一个拷贝，而不是该对象本身（该条可以归为第一条中的一个特例）&lt;/p&gt;

&lt;p&gt;当然不完全遵守上面的原则也能够创建immutable的类，比如String的hashcode就不是final的，但它能保证每次调用它的值都是一致的，无论你多少次计算这个值，它都是一致的，因为这些值的是通过计算final的属性得来的！&lt;/p&gt;

&lt;p&gt;另外，如果你的Java类中存在很多可选的和强制性的字段，你也可以使用建造者模式来创建一个immutable的类。&lt;/p&gt;

&lt;p&gt;下面是一个例子：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public final class Contacts {
 
    private final String name;
    private final String mobile;
 
    public Contacts(String name, String mobile) {
        this.name = name;
        this.mobile = mobile;
    }
   
    public String getName(){
        return name;
    }
   
    public String getMobile(){
        return mobile;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们为类添加了final修饰，从而避免因为继承和多态引起的immutable风险。
上面是最简单的一种实现immutable类的方式，可以看到它的所有属性都是final的。&lt;/p&gt;

&lt;p&gt;有时候你要实现的immutable类中可能包含mutable的类，比如java.util.Date,尽管你将其设置成了final的，但是它的值还是可以被修改的，为了避免这个问题，我们建议返回给用户该对象的一个拷贝，这也是Java的最佳实践之一。下面是一个创建包含mutable类对象的immutable类的例子：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public final class ImmutableReminder{
    private final Date remindingDate;
   
    public ImmutableReminder (Date remindingDate) {
        if(remindingDate.getTime() &amp;lt; System.currentTimeMillis()){
            throw new IllegalArgumentException(&amp;quot;Can not set reminder” +
                        “ for past time: &amp;quot; + remindingDate);
        }
        this.remindingDate = new Date(remindingDate.getTime());
    }
   
    public Date getRemindingDate() {
        return (Date) remindingDate.clone();
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的getRemindingDate()方法可以看到，返回给用户的是类中的remindingDate属性的一个拷贝，这样的话如果别人通过getRemindingDate()方法获得了一个Date对象，然后修改了这个Date对象的值，那么这个值的修改将不会导致ImmutableReminder类对象中remindingDate值的修改。
使用Immutable类的好处：
1）Immutable对象是线程安全的，可以不用被synchronize就在并发环境中共享&lt;/p&gt;

&lt;p&gt;2）Immutable对象简化了程序开发，因为它无需使用额外的锁机制就可以在线程间共享&lt;/p&gt;

&lt;p&gt;3）Immutable对象提高了程序的性能，因为它减少了synchroinzed的使用&lt;/p&gt;

&lt;p&gt;4）Immutable对象是可以被重复使用的，你可以将它们缓存起来重复使用，就像字符串字面量和整型数字一样。你可以使用静态工厂方法来提供类似于valueOf（）这样的方法，它可以从缓存中返回一个已经存在的Immutable对象，而不是重新创建一个。&lt;/p&gt;

&lt;p&gt;immutable也有一个缺点就是会制造大量垃圾，由于他们不能被重用而且对于它们的使用就是”用“然后”扔“，字符串就是一个典型的例子，它会创造很多的垃圾，给垃圾收集带来很大的麻烦。当然这只是个极端的例子，合理的使用immutable对象会创造很大的价值。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Spring Boot App with Elastic Search Indexing Service</title>
      <link>http://xmxiaohuilin.github.io/code/ElasticSearch/</link>
      <pubDate>Mon, 10 Aug 2015 23:56:15 -0700</pubDate>
      
      <guid>http://xmxiaohuilin.github.io/code/ElasticSearch/</guid>
      <description>

&lt;p&gt;This article shows an example to build a bridge between Spring-Boot App and Elastic Search Indexing Service.&lt;/p&gt;

&lt;h2 id=&#34;1-elastic-search-install&#34;&gt;1. Elastic Search Install&lt;/h2&gt;

&lt;p&gt;Install elastic search is very easy&lt;/p&gt;

&lt;h3 id=&#34;install-elastic-search&#34;&gt;Install Elastic Search&lt;/h3&gt;

&lt;h4 id=&#34;start-elastic-search&#34;&gt;Start Elastic Search&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;    # windows: cd yourPath: service install
                            service start
                            service stop
    # Mac: cd $ELASTIC_HOME: elasticsearch
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;check-your-service-by-input-the-url-localhost-9200-in-your-browser&#34;&gt;Check your service by input the url &lt;code&gt;localhost:9200&lt;/code&gt; in your browser.&lt;/h4&gt;

&lt;h4 id=&#34;cluster-name&#34;&gt;Cluster Name&lt;/h4&gt;

&lt;p&gt;If cluster name is not &amp;ldquo;elasticsearch&amp;rdquo;, it may cause the run failed when your Java code trying to build elastic search instance. There should be an exception( NoNodeClientException: None of node configed) when your indexing the data.&lt;/p&gt;

&lt;p&gt;Please change your cluster name into &amp;ldquo;elasticsearch&amp;rdquo; in your elasticsearch install path.
 $ELASTIC_HOME/config/elasticsearch.yml : clustername = elasticsearch&lt;/p&gt;

&lt;h2 id=&#34;2-creat-index-by-spring-data-elasticsearch-api&#34;&gt;2. Creat Index by Spring-data-elasticsearch API&lt;/h2&gt;

&lt;p&gt;Here is a example from my project. It shows how I creat an index for music by Bulk method, which is provided by Elastic Java API.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Service
public class MusicIndexingService {

	private final static Logger logger = Logger
			.getLogger(MusicIndexingService.class);

	@Autowired	
	private Client client ;
	
	private ObjectMapper mapper = new ObjectMapper();

	/**
	 * The bulk index method
	 * @param musicCollection for index
	 */
	public void bulkIndex(List&amp;lt;IndexedMusic&amp;gt; musicCollection) {
		client.delete(new DeleteRequest(&amp;quot;musics&amp;quot;));
		logger.info(&amp;quot;Indexing bulk request of &amp;quot; + musicCollection.size()
				+ &amp;quot; documents&amp;quot;);
		BulkRequestBuilder bulkRequest = client.prepareBulk();
		for (IndexedMusic music : musicCollection) {
			String json = null;
			try {
				json = mapper.writeValueAsString(music);
			} catch (JsonProcessingException e) {
				throw new RuntimeException(e);
			}
			bulkRequest.add(client.prepareIndex(&amp;quot;musics&amp;quot;, &amp;quot;music&amp;quot;,
					UUID.randomUUID().toString()).setSource(json));
		}
		BulkResponse response = bulkRequest.execute().actionGet();
		if (response.hasFailures()) {
			throw new RuntimeException(
					&amp;quot;there was an error indexing the bulk request of &amp;quot;
							+ musicCollection.size() + &amp;quot; documents: &amp;quot; +response.buildFailureMessage());
		}
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;## 3. Search the index:
 Search a music by name.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
	 * This is keyword search method in comment contents field in music object
	 * @param keyword
	 * @return
	 */
	public List&amp;lt;Music&amp;gt; findMusic(String keyword) {
		QueryBuilder matchquery = QueryBuilders.fuzzyLikeThisFieldQuery(
				&amp;quot;commentContents&amp;quot;).likeText(keyword);
		SearchRequestBuilder requestBuilder = client.prepareSearch(&amp;quot;musics&amp;quot;)
				.setQuery(matchquery);
		SearchResponse response = requestBuilder.execute().actionGet();
		SearchHits hits = response.getHits();
		List&amp;lt;String&amp;gt; musicIdsList = new ArrayList&amp;lt;String&amp;gt;();
		Iterator&amp;lt;SearchHit&amp;gt; iterator = hits.iterator();
		while (iterator.hasNext()) {
			musicIdsList.add(iterator.next().getSource().get(&amp;quot;id&amp;quot;).toString());
		}
		return (List&amp;lt;Music&amp;gt;) musicRepository.findAll(musicIdsList);
	}

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Architecture Design on Social Music Search project</title>
      <link>http://xmxiaohuilin.github.io/code/SpringBoot/</link>
      <pubDate>Sun, 09 Aug 2015 10:56:15 -0700</pubDate>
      
      <guid>http://xmxiaohuilin.github.io/code/SpringBoot/</guid>
      <description>

&lt;h2 id=&#34;framework&#34;&gt;Framework&lt;/h2&gt;

&lt;h4 id=&#34;why-spring-boot&#34;&gt;Why Spring Boot?&lt;/h4&gt;

&lt;p&gt;Spring framework goes every where in current enterprise application. However, most of people are familiar with Spring MVC. Here I just want to introduce a new Spring Boot project. Hear what its official document said:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Spring Boot makes it easy to create stand-alone, production-grade Spring based Applications that you can &amp;ldquo;just run&amp;rdquo;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Yes, unlike Spring MVC, the Spring Boot require less configuration and easier to deploy on remote virtual machine or cloud computing platform. Spring Boot has following features:&lt;/p&gt;

&lt;h4 id=&#34;features&#34;&gt;Features&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Create stand-alone Spring applications&lt;/li&gt;
&lt;li&gt;Embed Tomcat, Jetty or Undertow directly (no need to deploy WAR files)&lt;/li&gt;
&lt;li&gt;Provide opinionated &amp;lsquo;starter&amp;rsquo; POMs to simplify your Maven configuration&lt;/li&gt;
&lt;li&gt;Automatically configure Spring whenever possible&lt;/li&gt;
&lt;li&gt;Provide production-ready features such as metrics, health checks and externalized configuration&lt;/li&gt;
&lt;li&gt;Absolutely no code generation and no requirement for XML configuration&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;three-layers-should-be-enough-for-everybody&#34;&gt;Three Layers Should Be Enough for Everybody&lt;/h4&gt;

&lt;p&gt;If think about the responsibilities of a web application, we notice that a web application has the following “concerns”:&lt;/p&gt;

&lt;p&gt;It needs to process the user’s input and return the correct response back to the user.&lt;br /&gt;
It needs an exception handling mechanism that provides reasonable error messages to the user.&lt;br /&gt;
It needs a transaction management strategy.
It needs to handle both authentication and authorization.&lt;br /&gt;
It needs to implement the business logic of the application.&lt;br /&gt;
It needs to communicate with the used data storage and other external resources.&lt;/p&gt;

&lt;p&gt;We can fulfil all these concerns by using “only” three layers. These layers are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;The web layer&lt;/strong&gt; is the uppermost layer of a web application. It is responsible of processing user’s input and returning the correct response back to the user. The web layer must also handle the exceptions thrown by the other layers. Because the web layer is the entry point of our application, it must take care of authentication and act as a first line of defense against unauthorized users.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The service layer&lt;/strong&gt; resides below the web layer. It acts as a transaction boundary and contains both application and infrastructure services. The application services provides the public API of the service layer. They also act as a transaction boundary and are responsible of authorization. The infrastructure services contain the “plumbing code” that communicates with external resources such as file systems, databases, or email servers. Often these methods are used by more than a one application service.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The repository layer&lt;/strong&gt; is the lowest layer of a web application. It is responsible of communicating with the used data storage.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://xmxiaohuilin.github.io/media/spring/spring-web-application-layers.png&#34;&gt;&lt;/p&gt;

&lt;h2 id=&#34;backend-design-detail&#34;&gt;Backend Design Detail&lt;/h2&gt;

&lt;p&gt;Here is how I design my Social Music Search project with Spring Boot:&lt;/p&gt;

&lt;h3 id=&#34;restful-serivce&#34;&gt;RESTful Serivce&lt;/h3&gt;

&lt;p&gt;Do the backend and frontend communication&lt;/p&gt;

&lt;h5 id=&#34;spring-data-rest&#34;&gt;Spring-Data-REST&lt;/h5&gt;

&lt;p&gt;Package:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Config: ApplicationConfig;&lt;/li&gt;
&lt;li&gt;controller: call services and tranfer data as JSON format to the frondend&lt;/li&gt;
&lt;li&gt;service: call different service from mongodb or elastic search&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;database-service&#34;&gt;Database Service&lt;/h3&gt;

&lt;p&gt;Non-SQL database, MongoDB, to be the database solution&lt;/p&gt;

&lt;h5 id=&#34;spring-data-mongodb&#34;&gt;Spring-Data-MongoDB&lt;/h5&gt;

&lt;p&gt;Package:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Config: MongoDBConfig;&lt;/li&gt;
&lt;li&gt;mongodb.service&lt;/li&gt;
&lt;li&gt;mongodb.repository;&lt;/li&gt;
&lt;li&gt;domain: Music, BulletComment, User, Genre&amp;hellip;;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;indexing-service&#34;&gt;Indexing service&lt;/h3&gt;

&lt;p&gt;Achieve the advanced search function&lt;/p&gt;

&lt;h5 id=&#34;spring-data-elasticsearch&#34;&gt;Spring-Data-ElasticSearch&lt;/h5&gt;

&lt;p&gt;Package:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Config: ElasticSearchConfig; (port:9300)&lt;/li&gt;
&lt;li&gt;index.service&lt;/li&gt;
&lt;li&gt;index.repository;&lt;/li&gt;
&lt;li&gt;index.domain: Indexed Music;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;spring-boot-app-configuration&#34;&gt;Spring Boot App Configuration&lt;/h2&gt;

&lt;p&gt;The Spring Boot requires some basic configuration and set up the bootstrap entrance:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;It doesn&amp;rsquo;t need &lt;code&gt;web.xml&lt;/code&gt; whic is common for Spring MVC;&lt;/li&gt;
&lt;li&gt;Set up the bootstrap by Maven plugin.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Bootstrap Main function (Entrance of Spring Boot App): MusicSearchApplication;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Spring Configuration (config package)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ApplicationConfig
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Configuration
@PropertySource(&amp;quot;classpath:application.properties&amp;quot;) 
    // point out the application.properties as configuration source
public class ApplicationConfig {
    public @Bean LoggingEventListener mongoEventListener() {
        return new LoggingEventListener();
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;WebMVCConfig
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;@Configuration
@ComponentScan({&amp;quot;com.musicSearch.core.controller&amp;quot;,
    &amp;quot;com.musicSearch.core.service&amp;quot;, &amp;quot;com.musicSearch.core.domain&amp;quot;}) 
// here is important to do component scan
public class WebMVCConfig extends WebMvcConfigurerAdapter {
    @Override
    public void addViewControllers(ViewControllerRegistry registry) {
        registry.addViewController(&amp;quot;/static&amp;quot;)
                .setViewName(&amp;quot;forward:/index.html&amp;quot;);
        // point out the .css/.js or other static files target and default home page
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;ApplicationInitializer: Core entrance configuration
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Configuration
@EnableAutoConfiguration
@Import({ MongoDBConfig.class, ElasticSearchConfig.class,
        ApplicationConfig.class, WebMVCConfig.class,
        RepositoryRestMvcConfiguration.class })
public class MusicSearchApplication extends SpringBootServletInitializer {
    public static void main(String[] args) {
        SpringApplication.run(MusicSearchApplication.class, args);
    }
    @Override
    protected SpringApplicationBuilder configure(
            SpringApplicationBuilder application) {
        return application.sources(MusicSearchApplication.class);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://projects.spring.io/spring-boot/&#34;&gt;Spring Official Site&lt;/a&gt;
&lt;/br&gt;
&lt;a href=&#34;http://www.petrikainulainen.net/software-development/design/understanding-spring-web-application-architecture-the-classic-way/&#34;&gt;Understanding Spring Web Application Architecture: The Classic Way&lt;/a&gt;
&lt;/br&gt;
&lt;a href=&#34;http://martinfowler.com/eaaCatalog/index.html&#34;&gt;Patterns of Enterprise Application Architecture&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Access Control</title>
      <link>http://xmxiaohuilin.github.io/2015/07/12/access-control/</link>
      <pubDate>Sun, 12 Jul 2015 00:03:07 -0700</pubDate>
      
      <guid>http://xmxiaohuilin.github.io/2015/07/12/access-control/</guid>
      <description>&lt;p&gt;Reading Note while reading Java Best Practice.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Access Level&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Private:&lt;/li&gt;
&lt;li&gt;Package-private: Default&lt;/li&gt;
&lt;li&gt;Protected:&lt;/li&gt;
&lt;li&gt;Public
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Make each class or member as inaccessiable as possible!&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Implements Serializable may leak this class in API.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Instance field and static field must not be public!
Lost the control of this field and not thread safety but may be okay for immutable final instance field.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;An array with not-zero length is mutable!
Cannnot return public static array field.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The only two ways to return above field is by establish a immutable list or create a public method returning clone object!&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Don&amp;rsquo;t expose the internal data field:
public class should not expose any mutable field;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>